# -*- coding: utf-8 -*-
"""Salinan dari LSTM bab 4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MHNciRT_WH8Zk_BHgGMqc5TDwgPoMhkF
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk membangun model LSTM
def build_lstm_model(input_shape):
    model = Sequential()
    model.add(LSTM(50, activation='relu', input_shape=input_shape))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mse')
    return model

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_test, y_pred, dataset_name, n_steps):
    plt.figure(figsize=(10, 6))
    plt.plot(y_test, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9, 11]

# Menyimpan hasil
results = []

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    scaler = MinMaxScaler()
    df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']] = scaler.fit_transform(df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']])
    data = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    for n_steps in time_steps_options:
        X, y = create_sequences(data, n_steps, 1)  # Tambahkan argumen n_steps_out=1
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Membangun dan melatih model LSTM
        model = build_lstm_model((n_steps, X.shape[2]))
        model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)

        # Memprediksi
        y_pred = model.predict(X_test, verbose=0)

        # Menghitung Mean Absolute Error (MAE)
        mae = mean_absolute_error(y_test, y_pred)

        # Menghitung R-squared (R2)
        r2 = r2_score(y_test, y_pred)

        # Menghitung BIAS
        bias = np.mean(y_pred - y_test)

        # Menyimpan hasil untuk timestep saat ini
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'MAE': mae,
            'R2': r2,
            'Bias': bias
        })

        # Visualisasi actual vs predicted
        plot_actual_vs_predicted(y_test, y_pred, name, n_steps)

# Menampilkan hasil
results_df = pd.DataFrame(results)
print(results_df)

# Pilih nilai timestep dengan MAE terendah sebagai nilai optimal
optimal_timestep = results_df.loc[results_df['MAE'].idxmin()]['Timestep']
print(f"Optimal Timestep: {optimal_timestep}")



!pip install tensorflow numpy pandas scikit-learn matplotlib

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_actual, y_pred, dataset_name, n_steps, data_type):
    plt.figure(figsize=(10, 6))
    plt.plot(y_actual, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep ({data_type} Data)')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9, 11]

# Menyimpan hasil
results = []

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    scaler = MinMaxScaler()
    df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']] = scaler.fit_transform(df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']])
    data = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    for n_steps in time_steps_options:
        X, y = create_sequences(data, n_steps, 1)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Definisi model LSTM
        model = Sequential()
        model.add(LSTM(50, activation='relu', input_shape=(n_steps, X.shape[2])))
        model.add(Dense(1))
        model.compile(optimizer='adam', loss='mse')

        # Training model
        model.fit(X_train, y_train, epochs=50, verbose=0)

        # Prediksi
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)

        # Denormalisasi hasil prediksi dan data aktual
        y_train_combined = np.hstack([X_train[:, -1, :-1], y_train.reshape(-1, 1)])
        y_pred_train_combined = np.hstack([X_train[:, -1, :-1], y_pred_train.reshape(-1, 1)])
        y_test_combined = np.hstack([X_test[:, -1, :-1], y_test.reshape(-1, 1)])
        y_pred_test_combined = np.hstack([X_test[:, -1, :-1], y_pred_test.reshape(-1, 1)])

        # Menambahkan kolom dummy untuk menjaga bentuk yang sesuai
        y_train_combined = np.hstack([y_train_combined, np.zeros((y_train_combined.shape[0], 1))])
        y_pred_train_combined = np.hstack([y_pred_train_combined, np.zeros((y_pred_train_combined.shape[0], 1))])
        y_test_combined = np.hstack([y_test_combined, np.zeros((y_test_combined.shape[0], 1))])
        y_pred_test_combined = np.hstack([y_pred_test_combined, np.zeros((y_pred_test_combined.shape[0], 1))])

        y_train_denorm = scaler.inverse_transform(y_train_combined)[:, -2]
        y_pred_train_denorm = scaler.inverse_transform(y_pred_train_combined)[:, -2]
        y_test_denorm = scaler.inverse_transform(y_test_combined)[:, -2]
        y_pred_test_denorm = scaler.inverse_transform(y_pred_test_combined)[:, -2]

        # Menghitung metrik evaluasi pada skala asli untuk data training
        mae_train = mean_absolute_error(y_train_denorm, y_pred_train_denorm)
        r2_train = r2_score(y_train_denorm, y_pred_train_denorm)
        bias_train = np.mean(y_pred_train_denorm - y_train_denorm)
        mape_train = np.mean(np.abs((y_train_denorm - y_pred_train_denorm) / y_train_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (training)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Train',
            'MAE': mae_train,
            'R-square': r2_train,
            'Bias': bias_train,
            'MAPE': mape_train
        })

        # Menghitung metrik evaluasi pada skala asli untuk data testing
        mae_test = mean_absolute_error(y_test_denorm, y_pred_test_denorm)
        r2_test = r2_score(y_test_denorm, y_pred_test_denorm)
        bias_test = np.mean(y_pred_test_denorm - y_test_denorm)
        mape_test = np.mean(np.abs((y_test_denorm - y_pred_test_denorm) / y_test_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (testing)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Test',
            'MAE': mae_test,
            'R-square': r2_test,
            'Bias': bias_test,
            'MAPE': mape_test
        })

        # Visualisasi actual vs predicted untuk data train dan test
        plot_actual_vs_predicted(y_train_denorm, y_pred_train_denorm, name, n_steps, 'Train')
        plot_actual_vs_predicted(y_test_denorm, y_pred_test_denorm, name, n_steps, 'Test')

# Menampilkan hasil
results_df = pd.DataFrame(results)
print(results_df)

# Pilih nilai timestep dengan MAE terendah sebagai nilai optimal untuk data test
optimal_timestep = results_df[results_df['Data Type'] == 'Test'].loc[results_df[results_df['Data Type'] == 'Test']['MAE'].idxmin()]['Timestep']
print(f"Optimal Timestep: {optimal_timestep}")

# Visualisasi Timestep terhadap MAE untuk setiap dataset
def plot_timestep_vs_metric(results_df, metric):
    datasets = results_df['Dataset'].unique()
    plt.figure(figsize=(12, 8))

    for dataset in datasets:
        data = results_df[(results_df['Dataset'] == dataset) & (results_df['Data Type'] == 'Test')]
        plt.plot(data['Timestep'], data[metric], marker='o', label=dataset)

    plt.title(f'Timestep vs {metric}')
    plt.xlabel('Timestep')
    plt.ylabel(metric)
    plt.legend()
    plt.grid(True)
    plt.show()

# Plot MAE terhadap timestep untuk setiap dataset
plot_timestep_vs_metric(results_df, 'MAE')

!pip install tensorflow numpy pandas scikit-learn matplotlib

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_test, y_pred, dataset_name, n_steps):
    plt.figure(figsize=(10, 6))
    plt.plot(y_test, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Fungsi untuk visualisasi time step dengan metrik tertentu
def plot_metric_vs_timestep(results_df, metric_name):
    plt.figure(figsize=(10, 6))
    for dataset_name in results_df['Dataset'].unique():
        dataset_results = results_df[results_df['Dataset'] == dataset_name]
        plt.plot(dataset_results['Timestep'], dataset_results[metric_name], marker='o', label=dataset_name)
    plt.title(f'{metric_name} vs. Timestep')
    plt.xlabel('Timestep')
    plt.ylabel(metric_name)
    plt.legend()
    plt.grid(True)
    plt.show()

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9, 11]

# Menyimpan hasil
results_train = []
results_test = []

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    scaler = MinMaxScaler()
    df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']] = scaler.fit_transform(df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']])
    data = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    for n_steps in time_steps_options:
        X, y = create_sequences(data, n_steps, 1)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Definisi model LSTM
        model = Sequential()
        model.add(LSTM(50, activation='relu', input_shape=(n_steps, X.shape[2])))
        model.add(Dense(1))
        model.compile(optimizer='adam', loss='mse')

        # Training model
        model.fit(X_train, y_train, epochs=50, verbose=0)

        # Prediksi
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)

        # Menghitung Mean Absolute Error (MAE) untuk train dan test
        mae_train = mean_absolute_error(y_train, y_pred_train)
        mae_test = mean_absolute_error(y_test, y_pred_test)

        # Menyimpan hasil untuk timestep saat ini
        results_train.append({
            'Dataset': name,
            'Timestep': n_steps,
            'MAE': mae_train
        })
        results_test.append({
            'Dataset': name,
            'Timestep': n_steps,
            'MAE': mae_test
        })

        # Visualisasi actual vs predicted untuk data test
        plot_actual_vs_predicted(y_test, y_pred_test, name, n_steps)

# Menampilkan hasil dan visualisasi
results_train_df = pd.DataFrame(results_train)
results_test_df = pd.DataFrame(results_test)

print("Train Results:")
print(results_train_df)

print("\nTest Results:")
print(results_test_df)

# Visualisasi MAE vs. Timestep
plot_metric_vs_timestep(results_test_df, 'MAE')

!pip install tensorflow numpy pandas scikit-learn matplotlib

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_actual, y_pred, dataset_name, n_steps, data_type):
    plt.figure(figsize=(10, 6))
    plt.plot(y_actual, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep ({data_type} Data)')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9, 11]

# Menyimpan hasil
results = []
k_folds = 5  # Number of folds for cross-validation

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    scaler = MinMaxScaler()
    df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']] = scaler.fit_transform(df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']])
    data = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    for n_steps in time_steps_options:
        X, y = create_sequences(data, n_steps, 1)

        # K-Fold Cross Validation
        kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)
        fold = 1

        for train_index, test_index in kf.split(X):
            X_train, X_test = X[train_index], X[test_index]
            y_train, y_test = y[train_index], y[test_index]

            # Definisi model LSTM
            model = Sequential()
            model.add(LSTM(50, activation='relu', input_shape=(n_steps, X.shape[2])))
            model.add(Dense(1))
            model.compile(optimizer='adam', loss='mse')

            # Training model
            model.fit(X_train, y_train, epochs=50, verbose=0)

            # Prediksi
            y_pred_train = model.predict(X_train)
            y_pred_test = model.predict(X_test)

            # Denormalisasi hasil prediksi dan data aktual
            y_train_combined = np.hstack([X_train[:, -1, :-1], y_train.reshape(-1, 1)])
            y_pred_train_combined = np.hstack([X_train[:, -1, :-1], y_pred_train.reshape(-1, 1)])
            y_test_combined = np.hstack([X_test[:, -1, :-1], y_test.reshape(-1, 1)])
            y_pred_test_combined = np.hstack([X_test[:, -1, :-1], y_pred_test.reshape(-1, 1)])

            # Menambahkan kolom dummy untuk menjaga bentuk yang sesuai
            y_train_combined = np.hstack([y_train_combined, np.zeros((y_train_combined.shape[0], 1))])
            y_pred_train_combined = np.hstack([y_pred_train_combined, np.zeros((y_pred_train_combined.shape[0], 1))])
            y_test_combined = np.hstack([y_test_combined, np.zeros((y_test_combined.shape[0], 1))])
            y_pred_test_combined = np.hstack([y_pred_test_combined, np.zeros((y_pred_test_combined.shape[0], 1))])

            y_train_denorm = scaler.inverse_transform(y_train_combined)[:, -2]
            y_pred_train_denorm = scaler.inverse_transform(y_pred_train_combined)[:, -2]
            y_test_denorm = scaler.inverse_transform(y_test_combined)[:, -2]
            y_pred_test_denorm = scaler.inverse_transform(y_pred_test_combined)[:, -2]

            # Menghitung metrik evaluasi pada skala asli untuk data training
            mae_train = mean_absolute_error(y_train_denorm, y_pred_train_denorm)
            r2_train = r2_score(y_train_denorm, y_pred_train_denorm)
            bias_train = np.mean(y_pred_train_denorm - y_train_denorm)
            mape_train = np.mean(np.abs((y_train_denorm - y_pred_train_denorm) / y_train_denorm)) * 100

            # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (training)
            results.append({
                'Dataset': name,
                'Timestep': n_steps,
                'Data Type': f'Train Fold {fold}',
                'MAE': mae_train,
                'R-square': r2_train,
                'Bias': bias_train,
                'MAPE': mape_train
            })

            # Menghitung metrik evaluasi pada skala asli untuk data testing
            mae_test = mean_absolute_error(y_test_denorm, y_pred_test_denorm)
            r2_test = r2_score(y_test_denorm, y_pred_test_denorm)
            bias_test = np.mean(y_pred_test_denorm - y_test_denorm)
            mape_test = np.mean(np.abs((y_test_denorm - y_pred_test_denorm) / y_test_denorm)) * 100

            # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (testing)
            results.append({
                'Dataset': name,
                'Timestep': n_steps,
                'Data Type': f'Test Fold {fold}',
                'MAE': mae_test,
                'R-square': r2_test,
                'Bias': bias_test,
                'MAPE': mape_test
            })

            # Visualisasi actual vs predicted untuk data train dan test
            plot_actual_vs_predicted(y_train_denorm, y_pred_train_denorm, name, n_steps, f'Train Fold {fold}')
            plot_actual_vs_predicted(y_test_denorm, y_pred_test_denorm, name, n_steps, f'Test Fold {fold}')

            fold += 1

# Menampilkan hasil
results_df = pd.DataFrame(results)
print(results_df)

# Pilih nilai timestep dengan MAE terendah sebagai nilai optimal untuk data test
optimal_timestep = results_df[results_df['Data Type'].str.contains('Test')].loc[results_df[results_df['Data Type'].str.contains('Test')]['MAE'].idxmin()]['Timestep']
print(f"Optimal Timestep: {optimal_timestep}")

!pip install tensorflow numpy pandas scikit-learn matplotlib

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_actual, y_pred, dataset_name, n_steps, data_type):
    plt.figure(figsize=(10, 6))
    plt.plot(y_actual, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep ({data_type} Data)')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9, 11]

# Menyimpan hasil
results = []
k_folds = 5  # Number of folds for cross-validation

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    scaler = MinMaxScaler()
    df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']] = scaler.fit_transform(df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']])
    data = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    for n_steps in time_steps_options:
        X, y = create_sequences(data, n_steps, 1)

        # K-Fold Cross Validation
        kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)

        fold_results = []  # Menyimpan hasil untuk setiap fold

        for fold, (train_index, test_index) in enumerate(kf.split(X), 1):
            X_train, X_test = X[train_index], X[test_index]
            y_train, y_test = y[train_index], y[test_index]

            # Definisi model LSTM
            model = Sequential()
            model.add(LSTM(50, activation='relu', input_shape=(n_steps, X.shape[2])))
            model.add(Dense(1))
            model.compile(optimizer='adam', loss='mse')

            # Training model
            model.fit(X_train, y_train, epochs=50, verbose=0)

            # Prediksi
            y_pred_train = model.predict(X_train)
            y_pred_test = model.predict(X_test)

            # Denormalisasi hasil prediksi dan data aktual
            y_train_combined = np.hstack([X_train[:, -1, :-1], y_train.reshape(-1, 1)])
            y_pred_train_combined = np.hstack([X_train[:, -1, :-1], y_pred_train.reshape(-1, 1)])
            y_test_combined = np.hstack([X_test[:, -1, :-1], y_test.reshape(-1, 1)])
            y_pred_test_combined = np.hstack([X_test[:, -1, :-1], y_pred_test.reshape(-1, 1)])

            # Menambahkan kolom dummy untuk menjaga bentuk yang sesuai
            y_train_combined = np.hstack([y_train_combined, np.zeros((y_train_combined.shape[0], 1))])
            y_pred_train_combined = np.hstack([y_pred_train_combined, np.zeros((y_pred_train_combined.shape[0], 1))])
            y_test_combined = np.hstack([y_test_combined, np.zeros((y_test_combined.shape[0], 1))])
            y_pred_test_combined = np.hstack([y_pred_test_combined, np.zeros((y_pred_test_combined.shape[0], 1))])

            y_train_denorm = scaler.inverse_transform(y_train_combined)[:, -2]
            y_pred_train_denorm = scaler.inverse_transform(y_pred_train_combined)[:, -2]
            y_test_denorm = scaler.inverse_transform(y_test_combined)[:, -2]
            y_pred_test_denorm = scaler.inverse_transform(y_pred_test_combined)[:, -2]

            # Menghitung metrik evaluasi pada skala asli untuk data training
            mae_train = mean_absolute_error(y_train_denorm, y_pred_train_denorm)
            r2_train = r2_score(y_train_denorm, y_pred_train_denorm)
            bias_train = np.mean(y_pred_train_denorm - y_train_denorm)
            mape_train = np.mean(np.abs((y_train_denorm - y_pred_train_denorm) / y_train_denorm)) * 100

            # Menghitung metrik evaluasi pada skala asli untuk data testing
            mae_test = mean_absolute_error(y_test_denorm, y_pred_test_denorm)
            r2_test = r2_score(y_test_denorm, y_pred_test_denorm)
            bias_test = np.mean(y_pred_test_denorm - y_test_denorm)
            mape_test = np.mean(np.abs((y_test_denorm - y_pred_test_denorm) / y_test_denorm)) * 100

            # Menyimpan hasil untuk fold saat ini dengan data denormalisasi (training dan testing)
            fold_results.append({
                'Fold': fold,
                'MAE Train': mae_train,
                'R2 Train': r2_train,
                'Bias Train': bias_train,
                'MAPE Train': mape_train,
                'MAE Test': mae_test,
                'R2 Test': r2_test,
                'Bias Test': bias_test,
                'MAPE Test': mape_test
            })

        # Rata-rata hasil dari setiap fold
        avg_results = pd.DataFrame(fold_results).mean().to_dict()
        avg_results['Dataset'] = name
        avg_results['Timestep'] = n_steps
        results.append(avg_results)

# Menampilkan hasil
results_df = pd.DataFrame(results)
print(results_df)

# Pilih nilai timestep dengan MAE terendah sebagai nilai optimal untuk data test
optimal_timestep = results_df.loc[results_df['MAE Test'].idxmin()]['Timestep']
print(f"Optimal Timestep: {optimal_timestep}")

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
import tensorflow as tf

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_actual, y_pred, dataset_name, n_steps, data_type):
    plt.figure(figsize=(10, 6))
    plt.plot(y_actual, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep ({data_type} Data)')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Fungsi untuk membangun model LSTM
def build_lstm_model(input_shape):
    model = Sequential()
    model.add(LSTM(50, activation='relu', input_shape=input_shape))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mse')
    return model

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9, 11]

# Menyimpan hasil
results = []

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    scaler = MinMaxScaler()
    df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']] = scaler.fit_transform(df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']])
    data = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    for n_steps in time_steps_options:
        X, y = create_sequences(data, n_steps, 1)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        model = build_lstm_model((X_train.shape[1], X_train.shape[2]))
        model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)

        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)

        # Denormalisasi hasil prediksi dan data aktual
        y_train_combined = np.hstack([X_train[:, -1, :-1], y_train.reshape(-1, 1)])
        y_pred_train_combined = np.hstack([X_train[:, -1, :-1], y_pred_train.reshape(-1, 1)])
        y_test_combined = np.hstack([X_test[:, -1, :-1], y_test.reshape(-1, 1)])
        y_pred_test_combined = np.hstack([X_test[:, -1, :-1], y_pred_test.reshape(-1, 1)])

        # Menambahkan kolom dummy untuk menjaga bentuk yang sesuai
        y_train_combined = np.hstack([y_train_combined, np.zeros((y_train_combined.shape[0], 1))])
        y_pred_train_combined = np.hstack([y_pred_train_combined, np.zeros((y_pred_train_combined.shape[0], 1))])
        y_test_combined = np.hstack([y_test_combined, np.zeros((y_test_combined.shape[0], 1))])
        y_pred_test_combined = np.hstack([y_pred_test_combined, np.zeros((y_pred_test_combined.shape[0], 1))])

        y_train_denorm = scaler.inverse_transform(y_train_combined)[:, -2]
        y_pred_train_denorm = scaler.inverse_transform(y_pred_train_combined)[:, -2]
        y_test_denorm = scaler.inverse_transform(y_test_combined)[:, -2]
        y_pred_test_denorm = scaler.inverse_transform(y_pred_test_combined)[:, -2]

        # Menghitung metrik evaluasi pada skala asli untuk data training
        mae_train = mean_absolute_error(y_train_denorm, y_pred_train_denorm)
        r2_train = r2_score(y_train_denorm, y_pred_train_denorm)
        bias_train = np.mean(y_pred_train_denorm - y_train_denorm)
        mape_train = np.mean(np.abs((y_train_denorm - y_pred_train_denorm) / y_train_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (training)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Train',
            'MAE': mae_train,
            'R-square': r2_train,
            'Bias': bias_train,
            'MAPE': mape_train
        })

        # Menghitung metrik evaluasi pada skala asli untuk data testing
        mae_test = mean_absolute_error(y_test_denorm, y_pred_test_denorm)
        r2_test = r2_score(y_test_denorm, y_pred_test_denorm)
        bias_test = np.mean(y_pred_test_denorm - y_test_denorm)
        mape_test = np.mean(np.abs((y_test_denorm - y_pred_test_denorm) / y_test_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (testing)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Test',
            'MAE': mae_test,
            'R-square': r2_test,
            'Bias': bias_test,
            'MAPE': mape_test
        })

        # Visualisasi actual vs predicted untuk data train dan test
        plot_actual_vs_predicted(y_train_denorm, y_pred_train_denorm, name, n_steps, 'Train')
        plot_actual_vs_predicted(y_test_denorm, y_pred_test_denorm, name, n_steps, 'Test')

# Menampilkan hasil
results_df = pd.DataFrame(results)
print(results_df)

# Pilih nilai timestep dengan MAE terendah sebagai nilai optimal untuk data test
optimal_timestep = results_df[results_df['Data Type'] == 'Test'].loc[results_df[results_df['Data Type'] == 'Test']['MAE'].idxmin()]['Timestep']
print(f"Optimal Timestep: {optimal_timestep}")

# Fungsi untuk menampilkan sampel hasil data train dan test yang sudah di denormalisasi
def display_sample_results(results_df, timestep, data_type='Test'):
    selected_results = results_df[(results_df['Timestep'] == timestep) & (results_df['Data Type'] == data_type)]

    if selected_results.empty:
        print(f"No results found for timestep {timestep} and data type {data_type}.")
        return

    for _, result in selected_results.iterrows():
        dataset = result['Dataset']
        n_steps = result['Timestep']

        print(f"\nSample Results for {data_type} Data ({dataset} with {n_steps} Timestep):")

        if data_type == 'Train':
            sample_results = pd.DataFrame({
                'Actual': y_train_denorm,
                'Predicted': y_pred_train_denorm
            }).head(10)
        else:
            sample_results = pd.DataFrame({
                'Actual': y_test_denorm,
                'Predicted': y_pred_test_denorm
            }).head(10)

        print(sample_results)

# Menampilkan hasil sampel data train dan test untuk timestep tertentu
display_sample_results(results_df, timestep=1, data_type='Train')
display_sample_results(results_df, timestep=1, data_type='Test')

# Fungsi untuk visualisasi Timestep terhadap MAE untuk setiap dataset
def plot_timestep_vs_metric(results_df, metric):
    datasets = results_df['Dataset'].unique()
    plt.figure(figsize=(12, 8))

    for dataset in datasets:
        data = results_df[(results_df['Dataset'] == dataset) & (results_df['Data Type'] == 'Test')]
        plt.plot(data['Timestep'], data[metric], marker='o', label=dataset)

    plt.title(f'Timestep vs {metric}')
    plt.xlabel('Timestep')
    plt.ylabel(metric)
    plt.legend()
    plt.grid(True)
    plt.show()

# Plot MAE terhadap timestep untuk setiap dataset
plot_timestep_vs_metric(results_df, 'MAE')

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_actual, y_pred, dataset_name, n_steps, data_type):
    plt.figure(figsize=(10, 6))
    plt.plot(y_actual, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep ({data_type} Data)')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Fungsi untuk membangun model LSTM
def build_lstm_model(input_shape):
    model = Sequential()
    model.add(LSTM(50, activation='relu', input_shape=input_shape))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mse')
    return model

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9, 11]

# Menyimpan hasil
results = []

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    scaler = MinMaxScaler()
    df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']] = scaler.fit_transform(df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']])
    data = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    for n_steps in time_steps_options:
        X, y = create_sequences(data, n_steps, 1)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Membangun dan melatih model LSTM
        model = build_lstm_model((X_train.shape[1], X_train.shape[2]))
        model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)

        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)

        # Denormalisasi hasil prediksi dan data aktual
        y_train_combined = np.hstack([X_train[:, -1, :-1], y_train.reshape(-1, 1)])
        y_pred_train_combined = np.hstack([X_train[:, -1, :-1], y_pred_train.reshape(-1, 1)])
        y_test_combined = np.hstack([X_test[:, -1, :-1], y_test.reshape(-1, 1)])
        y_pred_test_combined = np.hstack([X_test[:, -1, :-1], y_pred_test.reshape(-1, 1)])

        # Menambahkan kolom dummy untuk menjaga bentuk yang sesuai
        y_train_combined = np.hstack([y_train_combined, np.zeros((y_train_combined.shape[0], 1))])
        y_pred_train_combined = np.hstack([y_pred_train_combined, np.zeros((y_pred_train_combined.shape[0], 1))])
        y_test_combined = np.hstack([y_test_combined, np.zeros((y_test_combined.shape[0], 1))])
        y_pred_test_combined = np.hstack([y_pred_test_combined, np.zeros((y_pred_test_combined.shape[0], 1))])

        y_train_denorm = scaler.inverse_transform(y_train_combined)[:, -2]
        y_pred_train_denorm = scaler.inverse_transform(y_pred_train_combined)[:, -2]
        y_test_denorm = scaler.inverse_transform(y_test_combined)[:, -2]
        y_pred_test_denorm = scaler.inverse_transform(y_pred_test_combined)[:, -2]

        # Menghitung metrik evaluasi pada skala asli untuk data training
        mae_train = mean_absolute_error(y_train_denorm, y_pred_train_denorm)
        r2_train = r2_score(y_train_denorm, y_pred_train_denorm)
        bias_train = np.mean(y_pred_train_denorm - y_train_denorm)
        mape_train = np.mean(np.abs((y_train_denorm - y_pred_train_denorm) / y_train_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (training)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Train',
            'MAE': mae_train,
            'R-square': r2_train,
            'Bias': bias_train,
            'MAPE': mape_train
        })

        # Menghitung metrik evaluasi pada skala asli untuk data testing
        mae_test = mean_absolute_error(y_test_denorm, y_pred_test_denorm)
        r2_test = r2_score(y_test_denorm, y_pred_test_denorm)
        bias_test = np.mean(y_pred_test_denorm - y_test_denorm)
        mape_test = np.mean(np.abs((y_test_denorm - y_pred_test_denorm) / y_test_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (testing)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Test',
            'MAE': mae_test,
            'R-square': r2_test,
            'Bias': bias_test,
            'MAPE': mape_test
        })

        # Visualisasi actual vs predicted untuk data train dan test
        plot_actual_vs_predicted(y_train_denorm, y_pred_train_denorm, name, n_steps, 'Train')
        plot_actual_vs_predicted(y_test_denorm, y_pred_test_denorm, name, n_steps, 'Test')

        # Menampilkan beberapa sampel hasil denormalisasi untuk verifikasi
        print(f"\nSample Results for Train Data ({name} with {n_steps} Timestep):")
        print(pd.DataFrame({'Actual': y_train_denorm, 'Predicted': y_pred_train_denorm}).head(10))
        print(f"\nSample Results for Test Data ({name} with {n_steps} Timestep):")
        print(pd.DataFrame({'Actual': y_test_denorm, 'Predicted': y_pred_test_denorm}).head(10))

# Menampilkan hasil
results_df = pd.DataFrame(results)
print(results_df)

# Pilih nilai timestep dengan MAE terendah sebagai nilai optimal untuk data test
optimal_timestep = results_df[results_df['Data Type'] == 'Test'].loc[results_df[results_df['Data Type'] == 'Test']['MAE'].idxmin()]['Timestep']
print(f"Optimal Timestep: {optimal_timestep}")

# Fungsi untuk visualisasi Timestep terhadap MAE untuk setiap dataset
def plot_timestep_vs_metric(results_df, metric):
    datasets = results_df['Dataset'].unique()
    plt.figure(figsize=(12, 8))

    for dataset in datasets:
        data = results_df[(results_df['Dataset'] == dataset) & (results_df['Data Type'] == 'Test')]
        plt.plot(data['Timestep'], data[metric], marker='o', label=dataset)

    plt.title(f'Timestep vs {metric}')
    plt.xlabel('Timestep')
    plt.ylabel(metric)
    plt.legend()
    plt.grid(True)
    plt.show()

# Plot MAE terhadap timestep untuk setiap dataset
plot_timestep_vs_metric(results_df, 'MAE')

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_actual, y_pred, dataset_name, n_steps, data_type):
    plt.figure(figsize=(10, 6))
    plt.plot(y_actual, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep ({data_type} Data)')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Fungsi untuk membangun model LSTM
def build_lstm_model(input_shape):
    model = Sequential()
    model.add(LSTM(50, activation='relu', input_shape=input_shape))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mse')
    return model

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9, 11]

# Menyimpan hasil
results = []

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    df['tanggal'] = pd.to_datetime(df['tanggal'])

    # Pisahkan kolom tanggal
    dates = df['tanggal'].values
    data_numeric = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    # Lakukan scaling hanya pada data numerik
    scaler = MinMaxScaler()
    data_scaled = scaler.fit_transform(data_numeric)

    for n_steps in time_steps_options:
        X, y = create_sequences(data_scaled, n_steps, 1)

        X_train, X_test, y_train, y_test, dates_train, dates_test = train_test_split(X, y, dates[n_steps:], test_size=0.2, random_state=42)

        model = build_lstm_model((X_train.shape[1], X_train.shape[2]))
        model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)

        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)

        # Denormalisasi hasil prediksi dan data aktual
        # Menyusun kembali data yang akan didenormalisasi agar memiliki shape yang sesuai
        y_train_combined = np.concatenate((X_train[:, -1, :-1], y_train), axis=1)
        y_pred_train_combined = np.concatenate((X_train[:, -1, :-1], y_pred_train), axis=1)
        y_test_combined = np.concatenate((X_test[:, -1, :-1], y_test), axis=1)
        y_pred_test_combined = np.concatenate((X_test[:, -1, :-1], y_pred_test), axis=1)

        # Tambahkan kolom dummy
        y_train_combined = np.concatenate([y_train_combined, np.zeros((y_train_combined.shape[0], 1))], axis=1)
        y_pred_train_combined = np.concatenate([y_pred_train_combined, np.zeros((y_pred_train_combined.shape[0], 1))], axis=1)
        y_test_combined = np.concatenate([y_test_combined, np.zeros((y_test_combined.shape[0], 1))], axis=1)
        y_pred_test_combined = np.concatenate([y_pred_test_combined, np.zeros((y_pred_test_combined.shape[0], 1))], axis=1)

        y_train_denorm = scaler.inverse_transform(y_train_combined)[:, -2]
        y_pred_train_denorm = scaler.inverse_transform(y_pred_train_combined)[:, -2]
        y_test_denorm = scaler.inverse_transform(y_test_combined)[:, -2]
        y_pred_test_denorm = scaler.inverse_transform(y_pred_test_combined)[:, -2]

        # Menghitung metrik evaluasi pada skala asli untuk data training
        mae_train = mean_absolute_error(y_train_denorm, y_pred_train_denorm)
        r2_train = r2_score(y_train_denorm, y_pred_train_denorm)
        bias_train = np.mean(y_pred_train_denorm - y_train_denorm)
        mape_train = np.mean(np.abs((y_train_denorm - y_pred_train_denorm) / y_train_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (training)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Train',
            'MAE': mae_train,
            'R-square': r2_train,
            'Bias': bias_train,
            'MAPE': mape_train
        })

        # Menghitung metrik evaluasi pada skala asli untuk data testing
        mae_test = mean_absolute_error(y_test_denorm, y_pred_test_denorm)
        r2_test = r2_score(y_test_denorm, y_pred_test_denorm)
        bias_test = np.mean(y_pred_test_denorm - y_test_denorm)
        mape_test = np.mean(np.abs((y_test_denorm - y_pred_test_denorm) / y_test_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (testing)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Test',
            'MAE': mae_test,
            'R-square': r2_test,
            'Bias': bias_test,
            'MAPE': mape_test
        })

        # Visualisasi actual vs predicted untuk data train dan test
        plot_actual_vs_predicted(y_train_denorm, y_pred_train_denorm, name, n_steps, 'Train')
        plot_actual_vs_predicted(y_test_denorm, y_pred_test_denorm, name, n_steps, 'Test')

        # Membuat DataFrame untuk data actual dan predicted test dengan tanggal
        test_results_df = pd.DataFrame({
            'Date': dates_test,
            'Actual': y_test_denorm,
            'Predicted': y_pred_test_denorm
        })

        # Simpan DataFrame ke file CSV
        test_results_df.to_csv(f'{name}_test_results_timestep_{n_steps}.csv', index=False)

        print(f"Test results for {name} with {n_steps} timestep saved to {name}_test_results_timestep_{n_steps}.csv")

# Menampilkan hasil
results_df = pd.DataFrame(results)
print(results_df)

# Pilih nilai timestep dengan MAE terendah sebagai nilai optimal untuk data test
optimal_timestep = results_df[results_df['Data Type'] == 'Test'].loc[results_df[results_df['Data Type'] == 'Test']['MAE'].idxmin()]['Timestep']
print(f"Optimal Timestep: {optimal_timestep}")

# Plot MAE terhadap timestep untuk setiap dataset
def plot_timestep_vs_metric(results_df, metric):
    plt.figure(figsize=(12, 6))
    for dataset in results_df['Dataset'].unique():
        data = results_df[(results_df['Dataset'] == dataset) & (results_df['Data Type'] == 'Test')]
        plt.plot(data['Timestep'], data[metric], marker='o', label=dataset)

    plt.title(f'Timestep vs {metric}')
    plt.xlabel('Timestep')
    plt.ylabel(metric)
    plt.legend()
    plt.grid(True)
    plt.show()

# Plot MAE terhadap timestep untuk setiap dataset
plot_timestep_vs_metric(results_df, 'MAE')

# Fungsi untuk memplot MAE terhadap timestep untuk setiap dataset secara terpisah
def plot_timestep_vs_metric_separately(results_df, metric):
    plt.figure(figsize=(12, 6))
    for dataset in results_df['Dataset'].unique():
        data = results_df[(results_df['Dataset'] == dataset) & (results_df['Data Type'] == 'Test')]
        plt.figure(figsize=(10, 5))
        plt.plot(data['Timestep'], data[metric], marker='o', label=f'{dataset} {metric}')
        plt.title(f'{dataset} - Timestep vs {metric}')
        plt.xlabel('Timestep')
        plt.ylabel(metric)
        plt.legend()
        plt.grid(True)
        plt.show()

# Plot MAE terhadap timestep untuk setiap dataset secara terpisah
plot_timestep_vs_metric_separately(results_df, 'MAE')