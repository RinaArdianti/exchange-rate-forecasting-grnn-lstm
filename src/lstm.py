# -*- coding: utf-8 -*-
"""Salinan dari bab 4 grnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yf5UCbVnNTV3Cn7ck37ag0C1DhqAuOwv
"""

!pip install pyGRNN
from sklearn.model_selection import KFold
from pyGRNN import GRNN
from sklearn.preprocessing import MinMaxScaler
import numpy as np
import pandas as pd
from sklearn.metrics import r2_score
import matplotlib.pyplot as plt

def evaluate_grnn(X, y, n_steps_in, n_splits=5):
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)
    mae_scores = []
    mape_scores = []
    r2_scores = []
    bias_scores = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        # Flatten the 3D input data to 2D
        X_train_flattened = X_train.reshape(X_train.shape[0], -1)
        X_test_flattened = X_test.reshape(X_test.shape[0], -1)

        grnn = GRNN()
        grnn.fit(X_train_flattened, y_train)
        y_pred = grnn.predict(X_test_flattened)

        mae = np.mean(np.abs(y_test - y_pred))
        mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
        r2 = r2_score(y_test, y_pred)
        bias = np.mean(y_pred - y_test)

        mae_scores.append(mae)
        mape_scores.append(mape)
        r2_scores.append(r2)
        bias_scores.append(bias)

        # Visualisasi Actual vs. Prediksi
        # plt.figure(figsize=(10, 6))
        # plt.plot(y_test, label='Actual', marker='o')
        # plt.plot(y_pred, label='Predicted', marker='x')
        # plt.title('Actual vs. Predicted Values')
        # plt.xlabel('Data Point')
        # plt.ylabel('Value')
        # plt.legend()
        # plt.show()

    mae_mean = np.mean(mae_scores)
    mae_std = np.std(mae_scores)
    mape_mean = np.mean(mape_scores)
    mape_std = np.std(mape_scores)
    r2_mean = np.mean(r2_scores)
    r2_std = np.std(r2_scores)
    bias_mean = np.mean(bias_scores)
    bias_std = np.std(bias_scores)

    return mae_mean, mae_std, mape_mean, mape_std, r2_mean, r2_std, bias_mean, bias_std

# Mengubah dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Time step options for each dataset
time_steps_options = {
    'Yen': 1,
    'Yuan': 3,
    'Dollar': 5,
    'Yen' : 7,
    'Yuan' : 9,
    'Dollar' : 11
}

datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

results = []

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    scaler = MinMaxScaler()
    df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']] = scaler.fit_transform(df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']])
    data = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values
    n_steps_in = time_steps_options[name]
    n_steps_out = 1
    X, y = create_sequences(data, n_steps_in, n_steps_out)
    mae_mean, mae_std, mape_mean, mape_std, r2_mean, r2_std, bias_mean, bias_std = evaluate_grnn(X, y, n_steps_in, n_splits=5)
    results.append({
        'Dataset': name,
        'Time Step': n_steps_in,
        'MAE Mean': mae_mean,
        'MAE Std': mae_std,
        'MAPE Mean': mape_mean,
        'MAPE Std': mape_std,
        'R2 Mean': r2_mean,
        'R2 Std': r2_std,
        'Bias Mean': bias_mean,
        'Bias Std': bias_std
    })

# Menampilkan hasil percobaan
results_df = pd.DataFrame(results)
print(results_df)

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from pyGRNN import GRNN
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_test, y_pred, dataset_name, n_steps):
    plt.figure(figsize=(10, 6))
    plt.plot(y_test, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9,11]

# Menyimpan hasil
results = []

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    scaler = MinMaxScaler()
    df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']] = scaler.fit_transform(df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']])
    data = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    for n_steps in time_steps_options:
        X, y = create_sequences(data, n_steps, 1)  # Tambahkan argumen n_steps_out=1
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Flatten the 3D input data to 2D
        X_train_flattened = X_train.reshape(X_train.shape[0], -1)
        X_test_flattened = X_test.reshape(X_test.shape[0], -1)

        grnn = GRNN()
        grnn.fit(X_train_flattened, y_train)
        y_pred = grnn.predict(X_test_flattened)

        # Menghitung Mean Squared Error (MSE)
        mse = mean_squared_error(y_test, y_pred)

        # Menyimpan hasil untuk timestep saat ini
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'MSE': mse
        })

        # Visualisasi actual vs predicted
        plot_actual_vs_predicted(y_test, y_pred, name, n_steps)

# Menampilkan hasil
results_df = pd.DataFrame(results)
print(results_df)

# Pilih nilai timestep dengan MSE terendah sebagai nilai optimal
optimal_timestep = results_df.loc[results_df['MSE'].idxmin()]['Timestep']
print(f"Optimal Timestep: {optimal_timestep}")

!pip install pyGRNN
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from pyGRNN import GRNN
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_test, y_pred, dataset_name, n_steps):
    plt.figure(figsize=(10, 6))
    plt.plot(y_test, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9, 11]

# Menyimpan hasil
results = []

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    scaler = MinMaxScaler()
    df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']] = scaler.fit_transform(df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']])
    data = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    for n_steps in time_steps_options:
        X, y = create_sequences(data, n_steps, 1)  # Tambahkan argumen n_steps_out=1
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Flatten the 3D input data to 2D
        X_train_flattened = X_train.reshape(X_train.shape[0], -1)
        X_test_flattened = X_test.reshape(X_test.shape[0], -1)

        grnn = GRNN()
        grnn.fit(X_train_flattened, y_train)
        y_pred = grnn.predict(X_test_flattened)

        # Menghitung Mean Absolute Error (MAE), R-square, dan Bias
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        bias = np.mean(y_pred - y_test)

        # Menyimpan hasil untuk timestep saat ini
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'MAE': mae,
            'R-square': r2,
            'Bias': bias
        })

        # Visualisasi actual vs predicted
        plot_actual_vs_predicted(y_test, y_pred, name, n_steps)

# Menampilkan hasil
results_df = pd.DataFrame(results)
print(results_df)

# Pilih nilai timestep dengan MAE terendah sebagai nilai optimal
optimal_timestep = results_df.loc[results_df['MAE'].idxmin()]['Timestep']
print(f"Optimal Timestep: {optimal_timestep}")



!pip install pyGRNN
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from pyGRNN import GRNN
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_actual, y_pred, dataset_name, n_steps, data_type):
    plt.figure(figsize=(10, 6))
    plt.plot(y_actual, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep ({data_type} Data)')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9, 11]

# Menyimpan hasil
results = []

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    scaler = MinMaxScaler()
    df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']] = scaler.fit_transform(df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']])
    data = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    for n_steps in time_steps_options:
        X, y = create_sequences(data, n_steps, 1)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Flatten the 3D input data to 2D
        X_train_flattened = X_train.reshape(X_train.shape[0], -1)
        X_test_flattened = X_test.reshape(X_test.shape[0], -1)

        grnn = GRNN()
        grnn.fit(X_train_flattened, y_train)
        y_pred_train = grnn.predict(X_train_flattened)
        y_pred_test = grnn.predict(X_test_flattened)

        # Denormalisasi hasil prediksi dan data aktual
        y_train_combined = np.hstack([X_train[:, -1, :-1], y_train.reshape(-1, 1)])
        y_pred_train_combined = np.hstack([X_train[:, -1, :-1], y_pred_train.reshape(-1, 1)])
        y_test_combined = np.hstack([X_test[:, -1, :-1], y_test.reshape(-1, 1)])
        y_pred_test_combined = np.hstack([X_test[:, -1, :-1], y_pred_test.reshape(-1, 1)])

        # Menambahkan kolom dummy untuk menjaga bentuk yang sesuai
        y_train_combined = np.hstack([y_train_combined, np.zeros((y_train_combined.shape[0], 1))])
        y_pred_train_combined = np.hstack([y_pred_train_combined, np.zeros((y_pred_train_combined.shape[0], 1))])
        y_test_combined = np.hstack([y_test_combined, np.zeros((y_test_combined.shape[0], 1))])
        y_pred_test_combined = np.hstack([y_pred_test_combined, np.zeros((y_pred_test_combined.shape[0], 1))])

        y_train_denorm = scaler.inverse_transform(y_train_combined)[:, -2]
        y_pred_train_denorm = scaler.inverse_transform(y_pred_train_combined)[:, -2]
        y_test_denorm = scaler.inverse_transform(y_test_combined)[:, -2]
        y_pred_test_denorm = scaler.inverse_transform(y_pred_test_combined)[:, -2]

        # Menghitung metrik evaluasi pada skala asli untuk data training
        mae_train = mean_absolute_error(y_train_denorm, y_pred_train_denorm)
        r2_train = r2_score(y_train_denorm, y_pred_train_denorm)
        bias_train = np.mean(y_pred_train_denorm - y_train_denorm)

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (training)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Train',
            'MAE': mae_train,
            'R-square': r2_train,
            'Bias': bias_train
        })

        # Menghitung metrik evaluasi pada skala asli untuk data testing
        mae_test = mean_absolute_error(y_test_denorm, y_pred_test_denorm)
        r2_test = r2_score(y_test_denorm, y_pred_test_denorm)
        bias_test = np.mean(y_pred_test_denorm - y_test_denorm)

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (testing)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Test',
            'MAE': mae_test,
            'R-square': r2_test,
            'Bias': bias_test
        })

        # Visualisasi actual vs predicted untuk data train dan test
        plot_actual_vs_predicted(y_train_denorm, y_pred_train_denorm, name, n_steps, 'Train')
        plot_actual_vs_predicted(y_test_denorm, y_pred_test_denorm, name, n_steps, 'Test')

# Menampilkan hasil
results_df = pd.DataFrame(results)
print(results_df)

# Pilih nilai timestep dengan MAE terendah sebagai nilai optimal untuk data test
optimal_timestep = results_df[results_df['Data Type'] == 'Test'].loc[results_df[results_df['Data Type'] == 'Test']['MAE'].idxmin()]['Timestep']
print(f"Optimal Timestep: {optimal_timestep}")

!pip install pyGRNN
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from pyGRNN import GRNN
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_actual, y_pred, dataset_name, n_steps, data_type):
    plt.figure(figsize=(10, 6))
    plt.plot(y_actual, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep ({data_type} Data)')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9, 11]

# Menyimpan hasil
results = []

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    scaler = MinMaxScaler()
    df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']] = scaler.fit_transform(df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']])
    data = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    for n_steps in time_steps_options:
        X, y = create_sequences(data, n_steps, 1)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Flatten the 3D input data to 2D
        X_train_flattened = X_train.reshape(X_train.shape[0], -1)
        X_test_flattened = X_test.reshape(X_test.shape[0], -1)

        grnn = GRNN()
        grnn.fit(X_train_flattened, y_train)
        y_pred_train = grnn.predict(X_train_flattened)
        y_pred_test = grnn.predict(X_test_flattened)

        # Denormalisasi hasil prediksi dan data aktual
        y_train_combined = np.hstack([X_train[:, -1, :-1], y_train.reshape(-1, 1)])
        y_pred_train_combined = np.hstack([X_train[:, -1, :-1], y_pred_train.reshape(-1, 1)])
        y_test_combined = np.hstack([X_test[:, -1, :-1], y_test.reshape(-1, 1)])
        y_pred_test_combined = np.hstack([X_test[:, -1, :-1], y_pred_test.reshape(-1, 1)])

        # Menambahkan kolom dummy untuk menjaga bentuk yang sesuai
        y_train_combined = np.hstack([y_train_combined, np.zeros((y_train_combined.shape[0], 1))])
        y_pred_train_combined = np.hstack([y_pred_train_combined, np.zeros((y_pred_train_combined.shape[0], 1))])
        y_test_combined = np.hstack([y_test_combined, np.zeros((y_test_combined.shape[0], 1))])
        y_pred_test_combined = np.hstack([y_pred_test_combined, np.zeros((y_pred_test_combined.shape[0], 1))])

        y_train_denorm = scaler.inverse_transform(y_train_combined)[:, -2]
        y_pred_train_denorm = scaler.inverse_transform(y_pred_train_combined)[:, -2]
        y_test_denorm = scaler.inverse_transform(y_test_combined)[:, -2]
        y_pred_test_denorm = scaler.inverse_transform(y_pred_test_combined)[:, -2]

        # Menghitung metrik evaluasi pada skala asli untuk data training
        mae_train = mean_absolute_error(y_train_denorm, y_pred_train_denorm)
        r2_train = r2_score(y_train_denorm, y_pred_train_denorm)
        bias_train = np.mean(y_pred_train_denorm - y_train_denorm)
        mape_train = np.mean(np.abs((y_train_denorm - y_pred_train_denorm) / y_train_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (training)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Train',
            'MAE': mae_train,
            'R-square': r2_train,
            'Bias': bias_train,
            'MAPE': mape_train
        })

        # Menghitung metrik evaluasi pada skala asli untuk data testing
        mae_test = mean_absolute_error(y_test_denorm, y_pred_test_denorm)
        r2_test = r2_score(y_test_denorm, y_pred_test_denorm)
        bias_test = np.mean(y_pred_test_denorm - y_test_denorm)
        mape_test = np.mean(np.abs((y_test_denorm - y_pred_test_denorm) / y_test_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (testing)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Test',
            'MAE': mae_test,
            'R-square': r2_test,
            'Bias': bias_test,
            'MAPE': mape_test
        })

        # Visualisasi actual vs predicted untuk data train dan test
        plot_actual_vs_predicted(y_train_denorm, y_pred_train_denorm, name, n_steps, 'Train')
        plot_actual_vs_predicted(y_test_denorm, y_pred_test_denorm, name, n_steps, 'Test')

# Menampilkan hasil
results_df = pd.DataFrame(results)
print(results_df)

# Pilih nilai timestep dengan MAE terendah sebagai nilai optimal untuk data test
optimal_timestep = results_df[results_df['Data Type'] == 'Test'].loc[results_df[results_df['Data Type'] == 'Test']['MAE'].idxmin()]['Timestep']
print(f"Optimal Timestep: {optimal_timestep}")

# Fungsi untuk menampilkan sampel hasil data train dan test yang sudah di denormalisasi
def display_sample_results(results_df, timestep, data_type='Test'):
    selected_results = results_df[(results_df['Timestep'] == timestep) & (results_df['Data Type'] == data_type)]

    if selected_results.empty:
        print(f"No results found for timestep {timestep} and data type {data_type}.")
        return

    for _, result in selected_results.iterrows():
        dataset = result['Dataset']
        n_steps = result['Timestep']

        print(f"\nSample Results for {data_type} Data ({dataset} with {n_steps} Timestep):")

        if data_type == 'Train':
            sample_results = pd.DataFrame({
                'Actual': y_train_denorm,
                'Predicted': y_pred_train_denorm
            }).head(10)
        else:
            sample_results = pd.DataFrame({
                'Actual': y_test_denorm,
                'Predicted': y_pred_test_denorm
            }).head(10)

        print(sample_results)

# Menampilkan hasil sampel data train dan test untuk timestep tertentu
display_sample_results(results_df, timestep=1, data_type='Train')
display_sample_results(results_df, timestep=1, data_type='Test')

# Mengambil beberapa sampel (10) hasil actual dan predicted
sample_results_train = pd.DataFrame({
    'Actual': y_train_denorm,
    'Predicted': y_pred_train_denorm
}).head(10)

sample_results_test = pd.DataFrame({
    'Actual': y_test_denorm,
    'Predicted': y_pred_test_denorm
}).head(10)

# Menampilkan hasil sampel data train
print("\nSample Results for Train Data:")
print(sample_results_train)

# Menampilkan hasil sampel data test
print("\nSample Results for Test Data:")
print(sample_results_test)

# Menyimpan informasi tentang dataset dan timestep
#current_dataset = name
#current_timestep = n_steps

# Mengambil beberapa sampel (10) hasil actual dan predicted
#sample_results_train = pd.DataFrame({
 #   'Actual': y_train_denorm,
 #  'Predicted': y_pred_train_denorm
#}).head(10)

#sample_results_test = pd.DataFrame({
#   'Actual': y_test_denorm,
 #   'Predicted': y_pred_test_denorm
#}).head(10)

# Menampilkan hasil sampel data train
#print(f"\nSample Results for Train Data ({current_dataset} with {current_timestep} Timestep):")
#print(sample_results_train)

# Menampilkan hasil sampel data test
#print(f"\nSample Results for Test Data ({current_dataset} with {current_timestep} Timestep):")
#print(sample_results_test)

import matplotlib.pyplot as plt

# Fungsi untuk visualisasi Timestep terhadap MAE untuk setiap dataset
def plot_timestep_vs_metric(results_df, metric):
    datasets = results_df['Dataset'].unique()
    plt.figure(figsize=(12, 8))

    for dataset in datasets:
        data = results_df[(results_df['Dataset'] == dataset) & (results_df['Data Type'] == 'Test')]
        plt.plot(data['Timestep'], data[metric], marker='o', label=dataset)

    plt.title(f'Timestep vs {metric}')
    plt.xlabel('Timestep')
    plt.ylabel(metric)
    plt.legend()
    plt.grid(True)
    plt.show()

# Plot MAE terhadap timestep untuk setiap dataset
plot_timestep_vs_metric(results_df, 'MAE')

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from pyGRNN import GRNN
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_actual, y_pred, dataset_name, n_steps, data_type):
    plt.figure(figsize=(10, 6))
    plt.plot(y_actual, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep ({data_type} Data)')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9, 11]

# Menyimpan hasil
results = []

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    scaler = MinMaxScaler()
    df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']] = scaler.fit_transform(df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']])
    data = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    for n_steps in time_steps_options:
        X, y = create_sequences(data, n_steps, 1)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Flatten the 3D input data to 2D
        X_train_flattened = X_train.reshape(X_train.shape[0], -1)
        X_test_flattened = X_test.reshape(X_test.shape[0], -1)

        grnn = GRNN()
        grnn.fit(X_train_flattened, y_train)
        y_pred_train = grnn.predict(X_train_flattened)
        y_pred_test = grnn.predict(X_test_flattened)

        # Denormalisasi hasil prediksi dan data aktual
        y_train_combined = np.hstack([X_train[:, -1, :-1], y_train.reshape(-1, 1)])
        y_pred_train_combined = np.hstack([X_train[:, -1, :-1], y_pred_train.reshape(-1, 1)])
        y_test_combined = np.hstack([X_test[:, -1, :-1], y_test.reshape(-1, 1)])
        y_pred_test_combined = np.hstack([X_test[:, -1, :-1], y_pred_test.reshape(-1, 1)])

        # Menambahkan kolom dummy untuk menjaga bentuk yang sesuai
        y_train_combined = np.hstack([y_train_combined, np.zeros((y_train_combined.shape[0], 1))])
        y_pred_train_combined = np.hstack([y_pred_train_combined, np.zeros((y_pred_train_combined.shape[0], 1))])
        y_test_combined = np.hstack([y_test_combined, np.zeros((y_test_combined.shape[0], 1))])
        y_pred_test_combined = np.hstack([y_pred_test_combined, np.zeros((y_pred_test_combined.shape[0], 1))])

        y_train_denorm = scaler.inverse_transform(y_train_combined)[:, -2]
        y_pred_train_denorm = scaler.inverse_transform(y_pred_train_combined)[:, -2]
        y_test_denorm = scaler.inverse_transform(y_test_combined)[:, -2]
        y_pred_test_denorm = scaler.inverse_transform(y_pred_test_combined)[:, -2]

        # Menghitung metrik evaluasi pada skala asli untuk data training
        mae_train = mean_absolute_error(y_train_denorm, y_pred_train_denorm)
        r2_train = r2_score(y_train_denorm, y_pred_train_denorm)
        bias_train = np.mean(y_pred_train_denorm - y_train_denorm)
        mape_train = np.mean(np.abs((y_train_denorm - y_pred_train_denorm) / y_train_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (training)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Train',
            'MAE': mae_train,
            'R-square': r2_train,
            'Bias': bias_train,
            'MAPE': mape_train
        })

        # Menghitung metrik evaluasi pada skala asli untuk data testing
        mae_test = mean_absolute_error(y_test_denorm, y_pred_test_denorm)
        r2_test = r2_score(y_test_denorm, y_pred_test_denorm)
        bias_test = np.mean(y_pred_test_denorm - y_test_denorm)
        mape_test = np.mean(np.abs((y_test_denorm - y_pred_test_denorm) / y_test_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (testing)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Test',
            'MAE': mae_test,
            'R-square': r2_test,
            'Bias': bias_test,
            'MAPE': mape_test
        })

        # Visualisasi actual vs predicted untuk data train dan test
        plot_actual_vs_predicted(y_train_denorm, y_pred_train_denorm, name, n_steps, 'Train')
        plot_actual_vs_predicted(y_test_denorm, y_pred_test_denorm, name, n_steps, 'Test')

        # Menampilkan beberapa sampel hasil denormalisasi untuk verifikasi
        print(f"\nSample Results for Train Data ({name} with {n_steps} Timestep):")
        print(pd.DataFrame({'Actual': y_train_denorm, 'Predicted': y_pred_train_denorm}).head(10))
        print(f"\nSample Results for Test Data ({name} with {n_steps} Timestep):")
        print(pd.DataFrame({'Actual': y_test_denorm, 'Predicted': y_pred_test_denorm}).head(10))

# Menampilkan hasil
results_df = pd.DataFrame(results)
print(results_df)

# Pilih nilai timestep dengan MAE terendah sebagai nilai optimal untuk data test
optimal_timestep = results_df[results_df['Data Type'] == 'Test'].loc[results_df[results_df['Data Type'] == 'Test']['MAE'].idxmin()]['Timestep']
print(f"Optimal Timestep: {optimal_timestep}")

# Fungsi untuk visualisasi Timestep terhadap MAE untuk setiap dataset
def plot_timestep_vs_metric(results_df, metric):
    datasets = results_df['Dataset'].unique()
    plt.figure(figsize=(12, 8))

    for dataset in datasets:
        data = results_df[(results_df['Dataset'] == dataset) & (results_df['Data Type'] == 'Test')]
        plt.plot(data['Timestep'], data[metric], marker='o', label=dataset)

    plt.title(f'Timestep vs {metric}')
    plt.xlabel('Timestep')
    plt.ylabel(metric)
    plt.legend()
    plt.grid(True)
    plt.show()

# Plot MAE terhadap timestep untuk setiap dataset
plot_timestep_vs_metric(results_df, 'MAE')

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsRegressor

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_actual, y_pred, dataset_name, n_steps, data_type):
    plt.figure(figsize=(10, 6))
    plt.plot(y_actual, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep ({data_type} Data)')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Fungsi untuk membangun model GRNN
def build_grnn_model():
    return KNeighborsRegressor(n_neighbors=1)

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9, 11]

# Menyimpan hasil
results = []

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    df['tanggal'] = pd.to_datetime(df['tanggal'])

    # Pisahkan kolom tanggal
    dates = df['tanggal'].values
    data_numeric = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    # Lakukan scaling hanya pada data numerik
    scaler = MinMaxScaler()
    data_scaled = scaler.fit_transform(data_numeric)

    for n_steps in time_steps_options:
        X, y = create_sequences(data_scaled, n_steps, 1)

        X_train, X_test, y_train, y_test, dates_train, dates_test = train_test_split(X, y, dates[n_steps:], test_size=0.2, random_state=42)

        # Bentuk ulang X_train dan X_test untuk GRNN
        X_train = X_train.reshape(X_train.shape[0], -1)
        X_test = X_test.reshape(X_test.shape[0], -1)

        model = build_grnn_model()
        model.fit(X_train, y_train)

        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)

        # Denormalisasi hasil prediksi dan data aktual
        # Menyusun kembali data yang akan didenormalisasi agar memiliki shape yang sesuai
        y_train_combined = np.concatenate((X_train[:, -1].reshape(-1, 1), y_train), axis=1)
        y_pred_train_combined = np.concatenate((X_train[:, -1].reshape(-1, 1), y_pred_train.reshape(-1, 1)), axis=1)
        y_test_combined = np.concatenate((X_test[:, -1].reshape(-1, 1), y_test), axis=1)
        y_pred_test_combined = np.concatenate((X_test[:, -1].reshape(-1, 1), y_pred_test.reshape(-1, 1)), axis=1)

        # Tambahkan kolom dummy
        y_train_combined = np.concatenate([y_train_combined, np.zeros((y_train_combined.shape[0], 2))], axis=1)
        y_pred_train_combined = np.concatenate([y_pred_train_combined, np.zeros((y_pred_train_combined.shape[0], 2))], axis=1)
        y_test_combined = np.concatenate([y_test_combined, np.zeros((y_test_combined.shape[0], 2))], axis=1)
        y_pred_test_combined = np.concatenate([y_pred_test_combined, np.zeros((y_pred_test_combined.shape[0], 2))], axis=1)

        y_train_denorm = scaler.inverse_transform(y_train_combined)[:, -3]
        y_pred_train_denorm = scaler.inverse_transform(y_pred_train_combined)[:, -3]
        y_test_denorm = scaler.inverse_transform(y_test_combined)[:, -3]
        y_pred_test_denorm = scaler.inverse_transform(y_pred_test_combined)[:, -3]

        # Menghitung metrik evaluasi pada skala asli untuk data training
        mae_train = mean_absolute_error(y_train_denorm, y_pred_train_denorm)
        r2_train = r2_score(y_train_denorm, y_pred_train_denorm)
        bias_train = np.mean(y_pred_train_denorm - y_train_denorm)
        mape_train = np.mean(np.abs((y_train_denorm - y_pred_train_denorm) / y_train_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (training)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Train',
            'MAE': mae_train,
            'R-square': r2_train,
            'Bias': bias_train,
            'MAPE': mape_train
        })

        # Menghitung metrik evaluasi pada skala asli untuk data testing
        mae_test = mean_absolute_error(y_test_denorm, y_pred_test_denorm)
        r2_test = r2_score(y_test_denorm, y_pred_test_denorm)
        bias_test = np.mean(y_pred_test_denorm - y_test_denorm)
        mape_test = np.mean(np.abs((y_test_denorm - y_pred_test_denorm) / y_test_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (testing)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Test',
            'MAE': mae_test,
            'R-square': r2_test,
            'Bias': bias_test,
            'MAPE': mape_test
        })

        # Visualisasi actual vs predicted untuk data train dan test
        plot_actual_vs_predicted(y_train_denorm, y_pred_train_denorm, name, n_steps, 'Train')
        plot_actual_vs_predicted(y_test_denorm, y_pred_test_denorm, name, n_steps, 'Test')

        # Membuat DataFrame untuk data actual dan predicted test dengan tanggal
        test_results_df = pd.DataFrame({
            'Date': dates_test,
            'Actual': y_test_denorm,
            'Predicted': y_pred_test_denorm
        })

        # Simpan DataFrame ke file CSV
        test_results_df.to_csv(f'{name}_test_results_timestep_{n_steps}.csv', index=False)

        print(f"Test results for {name} with {n_steps} timestep saved to {name}_test_results_timestep_{n_steps}.csv")

# Menampilkan hasil
results_df = pd.DataFrame(results)
print(results_df)

# Pilih nilai timestep dengan MAE terendah sebagai nilai optimal untuk data test
optimal_timestep = results_df[results_df['Data Type'] == 'Test'].loc[results_df[results_df['Data Type'] == 'Test']['MAE'].idxmin()]['Timestep']
print(f"Optimal Timestep: {optimal_timestep}")

# Plot MAE terhadap timestep untuk setiap dataset
def plot_timestep_vs_metric(results_df, metric):
    plt.figure(figsize=(12, 6))
    for dataset in results_df['Dataset'].unique():
        data = results_df[(results_df['Dataset'] == dataset) & (results_df['Data Type'] == 'Test')]
        plt.plot(data['Timestep'], data[metric], marker='o', label=dataset)

    plt.title(f'Timestep vs {metric}')
    plt.xlabel('Timestep')
    plt.ylabel(metric)
    plt.legend()
    plt.grid(True)
    plt.show()

# Plot MAE terhadap timestep untuk setiap dataset
plot_timestep_vs_metric(results_df, 'MAE')

# Fungsi untuk memplot MAE terhadap timestep untuk setiap dataset secara terpisah
def plot_timestep_vs_metric_separately(results_df, metric):
    plt.figure(figsize=(12, 6))
    for dataset in results_df['Dataset'].unique():
        data = results_df[(results_df['Dataset'] == dataset) & (results_df['Data Type'] == 'Test')]
        plt.figure(figsize=(10, 5))
        plt.plot(data['Timestep'], data[metric], marker='o', label=f'{dataset} {metric}')
        plt.title(f'{dataset} - Timestep vs {metric}')
        plt.xlabel('Timestep')
        plt.ylabel(metric)
        plt.legend()
        plt.grid(True)
        plt.show()

# Plot MAE terhadap timestep untuk setiap dataset secara terpisah
plot_timestep_vs_metric_separately(results_df, 'MAE')

!pip install pyGRNN
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from pyGRNN import GRNN
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_actual, y_pred, dataset_name, n_steps, data_type):
    plt.figure(figsize=(10, 6))
    plt.plot(y_actual, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep ({data_type} Data)')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9, 11]

# Menyimpan hasil
results = []

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    scaler = MinMaxScaler()
    df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']] = scaler.fit_transform(df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']])
    data = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    for n_steps in time_steps_options:
        X, y = create_sequences(data, n_steps, 1)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Flatten the 3D input data to 2D
        X_train_flattened = X_train.reshape(X_train.shape[0], -1)
        X_test_flattened = X_test.reshape(X_test.shape[0], -1)

        grnn = GRNN()
        grnn.fit(X_train_flattened, y_train)
        y_pred_train = grnn.predict(X_train_flattened)
        y_pred_test = grnn.predict(X_test_flattened)

        # Denormalisasi hasil prediksi dan data aktual
        y_train_combined = np.hstack([X_train[:, -1, :-1], y_train.reshape(-1, 1)])
        y_pred_train_combined = np.hstack([X_train[:, -1, :-1], y_pred_train.reshape(-1, 1)])
        y_test_combined = np.hstack([X_test[:, -1, :-1], y_test.reshape(-1, 1)])
        y_pred_test_combined = np.hstack([X_test[:, -1, :-1], y_pred_test.reshape(-1, 1)])

        # Menambahkan kolom dummy untuk menjaga bentuk yang sesuai
        y_train_combined = np.hstack([y_train_combined, np.zeros((y_train_combined.shape[0], 1))])
        y_pred_train_combined = np.hstack([y_pred_train_combined, np.zeros((y_pred_train_combined.shape[0], 1))])
        y_test_combined = np.hstack([y_test_combined, np.zeros((y_test_combined.shape[0], 1))])
        y_pred_test_combined = np.hstack([y_pred_test_combined, np.zeros((y_pred_test_combined.shape[0], 1))])

        y_train_denorm = scaler.inverse_transform(y_train_combined)[:, -2]
        y_pred_train_denorm = scaler.inverse_transform(y_pred_train_combined)[:, -2]
        y_test_denorm = scaler.inverse_transform(y_test_combined)[:, -2]
        y_pred_test_denorm = scaler.inverse_transform(y_pred_test_combined)[:, -2]

        # Menghitung metrik evaluasi pada skala asli untuk data training
        mae_train = mean_absolute_error(y_train_denorm, y_pred_train_denorm)
        r2_train = r2_score(y_train_denorm, y_pred_train_denorm)
        bias_train = np.mean(y_pred_train_denorm - y_train_denorm)
        mape_train = np.mean(np.abs((y_train_denorm - y_pred_train_denorm) / y_train_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (training)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Train',
            'MAE': mae_train,
            'R-square': r2_train,
            'Bias': bias_train,
            'MAPE': mape_train
        })

        # Menghitung metrik evaluasi pada skala asli untuk data testing
        mae_test = mean_absolute_error(y_test_denorm, y_pred_test_denorm)
        r2_test = r2_score(y_test_denorm, y_pred_test_denorm)
        bias_test = np.mean(y_pred_test_denorm - y_test_denorm)
        mape_test = np.mean(np.abs((y_test_denorm - y_pred_test_denorm) / y_test_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (testing)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Test',
            'MAE': mae_test,
            'R-square': r2_test,
            'Bias': bias_test,
            'MAPE': mape_test
        })

        # Visualisasi actual vs predicted untuk data train dan test
        plot_actual_vs_predicted(y_train_denorm, y_pred_train_denorm, name, n_steps, 'Train')
        plot_actual_vs_predicted(y_test_denorm, y_pred_test_denorm, name, n_steps, 'Test')

        # Menyimpan hasil denormalisasi ke CSV untuk data testing
        test_results_df = pd.DataFrame({
            'Actual': y_test_denorm,
            'Predicted': y_pred_test_denorm
        })
        test_results_df.to_csv(f'{name}_test_results_timestep_{n_steps}.csv', index=False)

# Menampilkan hasil
results_df = pd.DataFrame(results)
print(results_df)

# Pilih nilai timestep dengan MAE terendah sebagai nilai optimal untuk data test
optimal_timestep = results_df[results_df['Data Type'] == 'Test'].loc[results_df[results_df['Data Type'] == 'Test']['MAE'].idxmin()]['Timestep']
print(f"Optimal Timestep: {optimal_timestep}")

# Fungsi untuk visualisasi Timestep terhadap MAE untuk setiap dataset
def plot_timestep_vs_metric(results_df, metric):
    datasets = results_df['Dataset'].unique()
    plt.figure(figsize=(12, 8))

    for dataset in datasets:
        data = results_df[(results_df['Dataset'] == dataset) & (results_df['Data Type'] == 'Test')]
        plt.plot(data['Timestep'], data[metric], marker='o', label=dataset)

    plt.title(f'Timestep vs {metric}')
    plt.xlabel('Timestep')
    plt.ylabel(metric)
    plt.legend()
    plt.grid(True)
    plt.show()

# Plot MAE terhadap timestep untuk setiap dataset
plot_timestep_vs_metric(results_df, 'MAE')

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsRegressor

# Fungsi untuk membuat dataset menjadi sequence
def create_sequences(data, n_steps_in, n_steps_out):
    X, y = [], []
    for i in range(len(data)):
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        if out_end_ix > len(data):
            break
        seq_x, seq_y = data[i:end_ix, :-1], data[end_ix:out_end_ix, -1]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

# Fungsi untuk visualisasi actual vs predicted
def plot_actual_vs_predicted(y_actual, y_pred, dataset_name, n_steps, data_type):
    plt.figure(figsize=(10, 6))
    plt.plot(y_actual, label='Actual', marker='o')
    plt.plot(y_pred, label='Predicted', marker='x')
    plt.title(f'Actual vs. Predicted Values for {dataset_name} with {n_steps} Timestep ({data_type} Data)')
    plt.xlabel('Data Point')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

# Fungsi untuk membangun model GRNN
def build_grnn_model():
    return KNeighborsRegressor(n_neighbors=1)

# Contoh data
datasets = {
    'Yen': 'Dataaset Kurs JYP1.csv',
    'Yuan': 'Dataset Kurs CNY.csv',
    'Dollar': 'Dataset Kurs USD1.csv'
}

# Time step options untuk setiap dataset
time_steps_options = [1, 3, 5, 7, 9, 11]

# Menyimpan hasil
results = []

for name, filepath in datasets.items():
    df = pd.read_csv(filepath)
    df['suku_bunga_acuan'] = df['suku_bunga_acuan'].str.replace('%', '').astype(float)
    df['inflasi'] = df['inflasi'].str.replace('%', '').astype(float)
    df['tanggal'] = pd.to_datetime(df['tanggal'])

    # Pisahkan kolom tanggal
    dates = df['tanggal'].values
    data_numeric = df[['suku_bunga_acuan', 'inflasi', 'kurs_beli', 'kurs_jual']].values

    # Lakukan scaling hanya pada data numerik
    scaler = MinMaxScaler()
    data_scaled = scaler.fit_transform(data_numeric)

    for n_steps in time_steps_options:
        X, y = create_sequences(data_scaled, n_steps, 1)

        X_train, X_test, y_train, y_test, dates_train, dates_test = train_test_split(X, y, dates[n_steps:], test_size=0.2, random_state=42)

        # Bentuk ulang X_train dan X_test untuk GRNN
        X_train = X_train.reshape(X_train.shape[0], -1)
        X_test = X_test.reshape(X_test.shape[0], -1)

        model = build_grnn_model()
        model.fit(X_train, y_train)

        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)

        # Denormalisasi hasil prediksi dan data aktual
        # Tambahkan kolom dummy untuk denormalisasi
        dummy_train = np.zeros((y_train.shape[0], data_numeric.shape[1] - 1))
        dummy_test = np.zeros((y_test.shape[0], data_numeric.shape[1] - 1))

        y_train_combined = np.concatenate((dummy_train, y_train), axis=1)
        y_pred_train_combined = np.concatenate((dummy_train, y_pred_train), axis=1)
        y_test_combined = np.concatenate((dummy_test, y_test), axis=1)
        y_pred_test_combined = np.concatenate((dummy_test, y_pred_test), axis=1)

        # Denormalisasi data
        y_train_denorm = scaler.inverse_transform(y_train_combined)[:, -1]
        y_pred_train_denorm = scaler.inverse_transform(y_pred_train_combined)[:, -1]
        y_test_denorm = scaler.inverse_transform(y_test_combined)[:, -1]
        y_pred_test_denorm = scaler.inverse_transform(y_pred_test_combined)[:, -1]

        # Menghitung metrik evaluasi pada skala asli untuk data training
        mae_train = mean_absolute_error(y_train_denorm, y_pred_train_denorm)
        r2_train = r2_score(y_train_denorm, y_pred_train_denorm)
        bias_train = np.mean(y_pred_train_denorm - y_train_denorm)
        mape_train = np.mean(np.abs((y_train_denorm - y_pred_train_denorm) / y_train_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (training)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Train',
            'MAE': mae_train,
            'R-square': r2_train,
            'Bias': bias_train,
            'MAPE': mape_train
        })

        # Menghitung metrik evaluasi pada skala asli untuk data testing
        mae_test = mean_absolute_error(y_test_denorm, y_pred_test_denorm)
        r2_test = r2_score(y_test_denorm, y_pred_test_denorm)
        bias_test = np.mean(y_pred_test_denorm - y_test_denorm)
        mape_test = np.mean(np.abs((y_test_denorm - y_pred_test_denorm) / y_test_denorm)) * 100

        # Menyimpan hasil untuk timestep saat ini dengan data denormalisasi (testing)
        results.append({
            'Dataset': name,
            'Timestep': n_steps,
            'Data Type': 'Test',
            'MAE': mae_test,
            'R-square': r2_test,
            'Bias': bias_test,
            'MAPE': mape_test
        })

        # Visualisasi actual vs predicted untuk data train dan test
        plot_actual_vs_predicted(y_train_denorm, y_pred_train_denorm, name, n_steps, 'Train')
        plot_actual_vs_predicted(y_test_denorm, y_pred_test_denorm, name, n_steps, 'Test')

        # Membuat DataFrame untuk data actual dan predicted test dengan tanggal
        test_results_df = pd.DataFrame({
            'Date': dates_test,
            'Actual': y_test_denorm,
            'Predicted': y_pred_test_denorm
        })

        # Simpan DataFrame ke file CSV
        test_results_df.to_csv(f'{name}_test_results_timestep_{n_steps}.csv', index=False)

        print(f"Test results for {name} with {n_steps} timestep saved to {name}_test_results_timestep_{n_steps}.csv")

# Menampilkan hasil
results_df = pd.DataFrame(results)
print(results_df)

# Pilih nilai timestep dengan MAE terendah sebagai nilai optimal untuk data test
optimal_timestep = results_df[results_df['Data Type'] == 'Test'].loc[results_df[results_df['Data Type'] == 'Test']['MAE'].idxmin()]['Timestep']
print(f"Optimal Timestep: {optimal_timestep}")

# Plot MAE terhadap timestep untuk setiap dataset
def plot_timestep_vs_metric(results_df, metric):
    plt.figure(figsize=(12, 6))
    for dataset in results_df['Dataset'].unique():
        data = results_df[(results_df['Dataset'] == dataset) & (results_df['Data Type'] == 'Test')]
        plt.plot(data['Timestep'], data[metric], marker='o', label=dataset)

    plt.title(f'Timestep vs {metric}')
    plt.xlabel('Timestep')
    plt.ylabel(metric)
    plt.legend()
    plt.grid(True)
    plt.show()

# Plot MAE terhadap timestep untuk setiap dataset
plot_timestep_vs_metric(results_df, 'MAE')